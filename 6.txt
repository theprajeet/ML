import numpy as np
import matplotlib.pyplot as plt

# Gaussian Kernel function
def gaussian_kernel(x, xi, tau):
    return np.exp(-np.sum((x - xi) ** 2) / (2 * tau ** 2))

# Locally Weighted Regression function
def locally_weighted_regression(x, X, y, tau):
    m = X.shape[0]
    
    # Compute weights for all training examples
    weights = np.array([gaussian_kernel(x, X[i], tau) for i in range(m)])
    
    # Create diagonal weight matrix
    W = np.diag(weights)
    
    # Compute theta using the weighted normal equation
    XTWX = X.T @ W @ X
    XTWy = X.T @ W @ y
    theta = np.linalg.inv(XTWX) @ XTWy
    
    # Predict y value for the input x
    return x @ theta

# Generate synthetic dataset (sine wave with noise)
np.random.seed(42)
X = np.linspace(0, 2 * np.pi, 100)
y = np.sin(X) + 0.1 * np.random.randn(100)

# Add bias term (intercept) to input features
X_bias = np.c_[np.ones(X.shape), X]

# Create test points for prediction
x_test = np.linspace(0, 2 * np.pi, 200)
x_test_bias = np.c_[np.ones(x_test.shape), x_test]

# Set kernel bandwidth (tau)
tau = 0.5

# Predict y values for each test point
y_pred = np.array([
    locally_weighted_regression(xi, X_bias, y, tau) for xi in x_test_bias
])

# Plot the original data and LWR fit
plt.figure(figsize=(10, 6))
plt.scatter(X, y, color='red', label='Training Data', alpha=0.7)
plt.plot(x_test, y_pred, color='blue', label=f'LWR Fit (tau={tau})', linewidth=2)
plt.xlabel('X', fontsize=12)
plt.ylabel('y', fontsize=12)
plt.title('Locally Weighted Regression', fontsize=14)
plt.legend(fontsize=10)
plt.grid(alpha=0.3)
plt.show()